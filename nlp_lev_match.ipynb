{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee9d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein as lev\n",
    "from fuzzywuzzy import fuzz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6742b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05930792",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c721dc",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c903970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "parent_chain = 'booker' # lower case and \"clean\"\n",
    "parent_chain_column = 'parent_chain_name'\n",
    "item_column = 'item_name'\n",
    "language_ = 'en'\n",
    "threshold_ = 82\n",
    "parent_chain_use = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02bcc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading raw data\n",
    "data = pd.read_csv('uk_booker_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, col_name, new_col_name):\n",
    "    # column values to lower case\n",
    "    df[new_col_name] = df[col_name].str.lower().str.strip()\n",
    "    # removes special characters\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z.% \\t])\", \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dad2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parent_chain_use:\n",
    "    # cleaning parent chain name as it has duplicated entries\n",
    "    df = clean_text(data, parent_chain_column, '{}_{}'.format(parent_chain_column, 'norm'))\n",
    "    # chain selection and columns to work on\n",
    "    df_nlp = df[df['parent_chain_name_norm'] == parent_chain]\n",
    "    df_nlp = df_nlp.loc[:, ['parent_chain_name_norm', item_column]].reset_index(drop=True)\n",
    "else:\n",
    "    df_nlp = data.loc[:, [item_column]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item name standardization\n",
    "df_nlp.rename(columns={'sku_name': 'item_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baee2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial products: 50587\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial products: {len(list(set(df_nlp['item_name'].unique())))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63524601",
   "metadata": {},
   "source": [
    "## 2. NLP Aplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a034ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language_ == 'en':\n",
    "    stop_words = stopwords.words('english')\n",
    "elif language_ == 'es':\n",
    "    stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b534fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_stop_words(df, col, stop_list):\n",
    "    df['{}_stop'.format(col)] = df[col].apply(lambda x: ' '.join([word for word in x.split() if x not in stop_list]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdca9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    text_lemma = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b9e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_clean = r'(pm \\d+\\w+)|(pm \\d+\\.\\d+)|(pm\\d+\\.\\d+)|(\\d+ pmp)|(pm\\d+)|( \\.+)|(pmp\\d+.\\d+)|(\\d+pmp)|(pmp \\d+)|(\\d+.\\d+ pm)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c9d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cleaning(df, stop_words, regex_clean):\n",
    "    # normalization\n",
    "    df = clean_text(df, 'item_name', 'item_name_norm')\n",
    "    # remove stop words\n",
    "    df = replace_stop_words(df, 'item_name_norm', stop_words)\n",
    "    # tokenize text\n",
    "    df['item_name_token'] = df['item_name_norm_stop'].apply(lambda x: word_tokenize(x))\n",
    "    # lemmatization\n",
    "    df['item_name_token_lemma'] = df['item_name_token'].apply(lambda x: word_lemmatizer(x))\n",
    "    # joining lemmas\n",
    "    df['product_name'] = df['item_name_token_lemma'].apply(lambda list_: ' '.join([word for word in list_]))\n",
    "    # cleaning product names with regex\n",
    "    df['product_name'] = df['product_name'].apply(lambda x: re.sub(regex_clean, \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d21f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = nlp_cleaning(df_nlp, stop_words, regex_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2f5a1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50587, 41819)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique items\n",
    "len(df_nlp.item_name.unique()), len(df_nlp.product_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8add5375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_chain_name_norm</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_name_norm</th>\n",
       "      <th>item_name_norm_stop</th>\n",
       "      <th>item_name_token</th>\n",
       "      <th>item_name_token_lemma</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booker</td>\n",
       "      <td>\\tAunt Bessie's Hearty &amp; Homely Dumpling Mix 140g</td>\n",
       "      <td>aunt bessies hearty  homely dumpling mix 140g</td>\n",
       "      <td>aunt bessies hearty homely dumpling mix 140g</td>\n",
       "      <td>[aunt, bessies, hearty, homely, dumpling, mix,...</td>\n",
       "      <td>[aunt, bessies, hearty, homely, dumpling, mix,...</td>\n",
       "      <td>aunt bessies hearty homely dumpling mix 140g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>booker</td>\n",
       "      <td>\\tBC Choc Fudge Brownie</td>\n",
       "      <td>bc choc fudge brownie</td>\n",
       "      <td>bc choc fudge brownie</td>\n",
       "      <td>[bc, choc, fudge, brownie]</td>\n",
       "      <td>[bc, choc, fudge, brownie]</td>\n",
       "      <td>bc choc fudge brownie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_chain_name_norm                                          item_name  \\\n",
       "0                 booker  \\tAunt Bessie's Hearty & Homely Dumpling Mix 140g   \n",
       "1                 booker                            \\tBC Choc Fudge Brownie   \n",
       "\n",
       "                                  item_name_norm  \\\n",
       "0  aunt bessies hearty  homely dumpling mix 140g   \n",
       "1                          bc choc fudge brownie   \n",
       "\n",
       "                            item_name_norm_stop  \\\n",
       "0  aunt bessies hearty homely dumpling mix 140g   \n",
       "1                         bc choc fudge brownie   \n",
       "\n",
       "                                     item_name_token  \\\n",
       "0  [aunt, bessies, hearty, homely, dumpling, mix,...   \n",
       "1                         [bc, choc, fudge, brownie]   \n",
       "\n",
       "                               item_name_token_lemma  \\\n",
       "0  [aunt, bessies, hearty, homely, dumpling, mix,...   \n",
       "1                         [bc, choc, fudge, brownie]   \n",
       "\n",
       "                                   product_name  \n",
       "0  aunt bessies hearty homely dumpling mix 140g  \n",
       "1                         bc choc fudge brownie  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079e7a5",
   "metadata": {},
   "source": [
    "## 3. Levenshtein Ratio Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485538b8",
   "metadata": {},
   "source": [
    "### 3.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d06377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uselful columns selection (item selected just for 'product_name' not be treated as array)\n",
    "df_lev = df_nlp.loc[:, ['product_name']]\n",
    "df_lev = df_lev.drop_duplicates('product_name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d5be91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aunt bessies hearty homely dumpling mix 140g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc choc fudge brownie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batchelors big super noodle chicken flavour 100g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batchelors condensed soup cream of chicken 295g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batchelors cream of tomato condensed soup 295g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_name\n",
       "0      aunt bessies hearty homely dumpling mix 140g\n",
       "1                             bc choc fudge brownie\n",
       "2  batchelors big super noodle chicken flavour 100g\n",
       "3   batchelors condensed soup cream of chicken 295g\n",
       "4    batchelors cream of tomato condensed soup 295g"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ = df_lev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ff18cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix creation --> null values\n",
    "matrix_ = np.zeros((len_, len_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c5133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41819, 41819)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9a4c",
   "metadata": {},
   "source": [
    "### 3.2 Applying Levenshtein Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c92ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659046561.363988"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "266c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, product_ in enumerate(df_lev['product_name']):\n",
    "    for j, match_ in enumerate(df_lev['product_name']):\n",
    "        matrix_[i][j] = fuzz.token_sort_ratio(match_, product_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84103cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12716.558963060379"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()-t1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f96692a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Levenshtein for 50K: 3.53 hours\n"
     ]
    }
   ],
   "source": [
    "if t/60 > 60:\n",
    "    print(f'Direct Levenshtein for 50K: {round((t/60)/60, 2)} hours')\n",
    "else:\n",
    "    print(f'Direct Levenshtein for 50K: {t/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1faadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix copy\n",
    "matrix_copy = matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb5ff4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.,  25.,  43., ...,  28.,  33.,  26.],\n",
       "       [ 25., 100.,  41., ...,  33.,  28.,  26.],\n",
       "       [ 43.,  41., 100., ...,  32.,  29.,  27.],\n",
       "       ...,\n",
       "       [ 28.,  33.,  32., ..., 100.,  23.,  21.],\n",
       "       [ 33.,  28.,  29., ...,  23., 100.,  30.],\n",
       "       [ 26.,  26.,  27., ...,  21.,  30., 100.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda35ca8",
   "metadata": {},
   "source": [
    "### 4. Matrix to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37c731",
   "metadata": {},
   "source": [
    "IDEA:\n",
    "\n",
    "* podria hacer un diccionario entre: product-index\n",
    "* por cada producto, tomo su fila\n",
    "* filtro por el threshold\n",
    "* traigo los similares de los matches actuales usando su index\n",
    "* integro al dataframe bajo condiciones ya establecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "649cf2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_list = list(df_lev['product_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb09a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with lev ratios\n",
    "df_ratios = pd.DataFrame(matrix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42c3f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41809</th>\n",
       "      <th>41810</th>\n",
       "      <th>41811</th>\n",
       "      <th>41812</th>\n",
       "      <th>41813</th>\n",
       "      <th>41814</th>\n",
       "      <th>41815</th>\n",
       "      <th>41816</th>\n",
       "      <th>41817</th>\n",
       "      <th>41818</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0  100.0   25.0   43.0   37.0   36.0   40.0   34.0   29.0   38.0   44.0  ...   \n",
       "1   25.0  100.0   41.0   35.0   33.0   33.0   33.0   35.0   36.0   49.0  ...   \n",
       "2   43.0   41.0  100.0   61.0   51.0   45.0   44.0   30.0   44.0   33.0  ...   \n",
       "3   37.0   35.0   61.0  100.0   84.0   34.0   32.0   28.0   34.0   34.0  ...   \n",
       "4   36.0   33.0   51.0   84.0  100.0   33.0   35.0   28.0   32.0   40.0  ...   \n",
       "\n",
       "   41809  41810  41811  41812  41813  41814  41815  41816  41817  41818  \n",
       "0   48.0   33.0   32.0   33.0   28.0   28.0   32.0   28.0   33.0   26.0  \n",
       "1   36.0   37.0   39.0   37.0   29.0   24.0   32.0   33.0   28.0   26.0  \n",
       "2   50.0   37.0   30.0   34.0   26.0   26.0   43.0   32.0   29.0   27.0  \n",
       "3   37.0   29.0   36.0   29.0   24.0   18.0   34.0   32.0   26.0   28.0  \n",
       "4   35.0   29.0   37.0   26.0   27.0   21.0   32.0   33.0   26.0   25.0  \n",
       "\n",
       "[5 rows x 41819 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d247082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group_track_df(groups_df, track_df, product, applicants_list):\n",
    "    if groups_df.shape[0] == 0:\n",
    "        group_id = 0\n",
    "    else:\n",
    "        group_id = groups_df['group_id'].max() + 1\n",
    "    if track_df.shape[0] == 0:\n",
    "        track_id = 0\n",
    "    else:\n",
    "        track_id = track_df['group_id'].max() + 1\n",
    "        \n",
    "    df_temp_group = pd.DataFrame({\n",
    "        'group_id': group_id,\n",
    "        'leader': product,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    df_temp_track = pd.DataFrame({\n",
    "        'group_id': track_id,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    \n",
    "    return df_temp_group, df_temp_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfac07",
   "metadata": {},
   "source": [
    "## Package similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "107b081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_extract(df, column, regex_):\n",
    "    \"\"\"\n",
    "    Extracts the package from a product name. Uses a regular expression for these.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: dataframe\n",
    "    - column: product name column where to look for packages\n",
    "    - regex_: regular expression formula to match patterns\n",
    "    \n",
    "    Output: a column with the package of the specified product name column\n",
    "    \"\"\"\n",
    "    packs = df[column].str.extract(regex_)\n",
    "    packs['package'] = packs[packs.columns[0:]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    packs = packs.loc[:, ['package']]\n",
    "    return packs.loc[:, ['package']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9991be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_package = r'(\\d+x\\d+\\w+)|(\\d+ x \\d+\\w+)|(\\d+\\.+\\d+\\w+)|(\\d+\\.+\\d+ \\w+)|(\\d+ ml)|(\\d+ g)|(\\d+\\w+)|(\\d+ \\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f25a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group(group_df, regex_, threshold_=85):\n",
    "    \"\"\"\n",
    "    From a group of products which are similar, compares if they share the same/similar package. For this, uses \n",
    "    \"package_extract\" function to extract the package of the \"leader\" product, and its similars; and then uses\n",
    "    fuzzywuzzy to compare the similarity of the packages. Finally, keeps the packages with similarity over a threshold\n",
    "    of 75 or the one specified by the user.\n",
    "    \n",
    "    Inputs:\n",
    "    - group_df: dataframe with a group of similar products\n",
    "    - regex_: regex formula to extract the package\n",
    "    - threshold_: threshold of similarity to compare package\n",
    "    \n",
    "    Output: a clean group of similar candidates\n",
    "    \"\"\"\n",
    "    group_df['package'] = package_extract(group_df, 'product_name', regex_)\n",
    "    group_df['package_match'] = package_extract(group_df, 'match', regex_)\n",
    "    group_df['package_ratio'] = group_df.apply(lambda x: fuzz.token_sort_ratio(x['package'], x['package_match']), axis=1)\n",
    "    group_df = group_df[group_df['package_ratio'] >= threshold_].copy()\n",
    "    group_df = group_df.loc[:, ['product_name', 'match', 'lev_ratio']]\n",
    "    group_df.reset_index(drop=True, inplace=True)\n",
    "    return group_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463bdfd",
   "metadata": {},
   "source": [
    "### 5. Identifying groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb951b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_concat_groups(groups_df, track_df, index_, applicants_list):\n",
    "    # verify if any of the applicants is already assigned to a group, if not:    \n",
    "    if track_df[track_df['member'].isin(applicants_list)].shape[0] == 0:\n",
    "        # create df for the group\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, applicants_list)\n",
    "        # concat group to the global groups df\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        # concat track group to track global groups df\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    else:\n",
    "        # get the group ids where all of the candidates are assigned\n",
    "        groups_id_list = list(track_df[track_df['member'].isin(applicants_list)]['group_id'].unique())\n",
    "        # locate where the group is\n",
    "        select_df = groups_df[groups_df['group_id'].isin(groups_id_list)]\n",
    "        # list of actual members of the group\n",
    "        already_members = list(pd.unique(select_df[['leader', 'member']].values.ravel('K')))\n",
    "        # union of already members + apliccants list --> idea: get a unique selection of a wider spectrum\n",
    "        concatenated_list = list(set(already_members + applicants_list))\n",
    "        # remove group from global groups and track dataframes\n",
    "        groups_df = groups_df[~groups_df['group_id'].isin(groups_id_list)].copy()\n",
    "        track_df = track_df[~track_df['group_id'].isin(groups_id_list)]\n",
    "        # re-create both: groups & track - global dfs\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, concatenated_list)\n",
    "        # add the new set to both: groups & track - global dfs\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    return groups_df, track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c045da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to match product names with index\n",
    "product_index_dict = dict(zip(product_name_list, df_ratios.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1a5058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to match indexes with product_names\n",
    "index_product_dict = dict(zip(df_ratios.columns, product_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d0f94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time before\n",
    "t_bef_group = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe definition\n",
    "groups_df = pd.DataFrame(columns=['group_id', 'leader', 'member'])\n",
    "track_df = pd.DataFrame(columns=['group_id', 'member'])\n",
    "\n",
    "# iterating for all products and defining final groups\n",
    "for product_, index_ in product_index_dict.items():\n",
    "    try:\n",
    "        # gets all levenshtein ratios of the product and the set\n",
    "        index_values = list(df_ratios.iloc[index_, :])\n",
    "        # dataframe with lev ratios\n",
    "        df_values = pd.DataFrame(data={'match': range(0, df_ratios.shape[0]), 'lev_ratio': index_values})\n",
    "        # adds product name column to melt\n",
    "        df_values.insert(0, 'product_name', index_)\n",
    "        # filter product lev ratios by threshold            \n",
    "        df_group = df_values[df_values['lev_ratio'] > 0.8].reset_index(drop=True)\n",
    "        \n",
    "        # cleaning group by applying package comparison (regex)\n",
    "        df_group['product_name'] = df_group['product_name'].map(index_product_dict)\n",
    "        df_group['match'] = df_group['match'].map(index_product_dict)\n",
    "        df_clean_group = clean_group(df_group, reg_package, threshold_=85)\n",
    "        # place back int values for better performance\n",
    "        df_clean_group['product_name'] = df_clean_group['product_name'].map(product_index_dict)\n",
    "        df_clean_group['match'] = df_clean_group['match'].map(product_index_dict)\n",
    "        # applicants list (all products - including \"leader\")\n",
    "        applicants_list = list(pd.unique(df_clean_group[['product_name', 'match']].values.ravel('K')))\n",
    "        groups_df, track_df = verify_and_concat_groups(groups_df, track_df, index_, applicants_list)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(f'Failed product: {product_}; Index: {index_}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to run\n",
    "t_run = time.time()-t_bef_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b30427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time to run: {round(t_run/60, 2)} minutes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99224ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c767f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52e7cc58",
   "metadata": {},
   "source": [
    "### 6. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add442ef",
   "metadata": {},
   "source": [
    "#### 6.1 Verify if any leader leads more than 1 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b16e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_df = groups_df.loc[:, ['group_id', 'leader']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_df[leaders_df['leader'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4868f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if leaders_df[leaders_df['leader'].duplicated() == True].shape[0] == 0:\n",
    "    print('Leaders lead correctly!')\n",
    "else:\n",
    "    print('Verify leaders please! They are repeated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527c681",
   "metadata": {},
   "source": [
    "#### 6.2 Verify if any product belongs to more than 1 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48423a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df = groups_df.loc[:, ['group_id', 'member']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df[members_df['member'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if members_df[members_df['member'].duplicated() == True].shape[0] == 0:\n",
    "    print('Members are assigned correctly!')\n",
    "else:\n",
    "    print('Verify members please! Some are assigned to more than 1 group!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336a235",
   "metadata": {},
   "source": [
    "#### 6.3 All products have been assigned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12676ae",
   "metadata": {},
   "source": [
    "##### on groups DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_list = list(index_product_dict.keys())\n",
    "all_products_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45155ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_assigned_products = pd.unique(groups_df[['leader', 'member']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95114704",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_groups = []\n",
    "for i in all_products_list:\n",
    "    if i not in groups_assigned_products:\n",
    "        not_in_groups.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a24bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products not assigned in groups_df: {len(not_in_groups)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960505f",
   "metadata": {},
   "source": [
    "##### On track DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_assigned_products = pd.unique(track_df[['group_id', 'member']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_track = []\n",
    "for i in all_products_list:\n",
    "    if i not in track_assigned_products:\n",
    "        not_in_track.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d11be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products not assigned in track_df: {len(not_in_track)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557006d6",
   "metadata": {},
   "source": [
    "##### Why not assigned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice_ in not_in_groups[:5]:\n",
    "    print(f'{indice_}: {index_product_dict[indice_]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e34a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice_ in not_in_track[:5]:\n",
    "    print(f'{indice_}: {index_product_dict[indice_]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d358d",
   "metadata": {},
   "source": [
    "### 7. Visualizing groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of unique groups: {len(groups_df[\"group_id\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6e2a7",
   "metadata": {},
   "source": [
    "#### 7.1 Replacing int product names with the actual name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df['leader'] = groups_df['leader'].map(index_product_dict)\n",
    "groups_df['member'] = groups_df['member'].map(index_product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = groups_df.sort_values(by=['leader', 'member']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178983f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.iloc[2320:2380, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17b682",
   "metadata": {},
   "source": [
    "##### Coca DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de496e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_df = groups_df[(groups_df['leader'].str.contains('coca'))|(groups_df['member'].str.contains('coca'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_index_dict['dbury caramilk button']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fe7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df_ratios.iloc[41866, :] > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_product_dict[41866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028545a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_df[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7109a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0768630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.to_csv('groups_nlp_lev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149aad8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94879573",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd99e6",
   "metadata": {},
   "source": [
    "### Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all levenshtein ratios of the product and the set\n",
    "df_values = df_ratios.iloc[100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the indexes of the products that have similarity measure over the threshold\n",
    "similar_indexes_list = list(np.where(df_values > 0.8)[0])\n",
    "similar_indexes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the selection of products that are similar (extended) and also their levenshtein ratios\n",
    "df_extended = df_ratios.iloc[similar_indexes_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b43373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds product name column to melt\n",
    "df_extended.insert(0, 'product_name', df_extended.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt dataframe\n",
    "df_melt = df_extended.melt(id_vars='product_name', var_name='match', value_name='lev_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter product lev ratios by threshold\n",
    "df_group = df_melt[df_melt['lev_ratio'] > 0.8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing product name to clarify the direction of similarities (product tha's being processed)\n",
    "df_group['product_name'] = index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb082d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates (matches)\n",
    "df_clean_group = df_group.drop_duplicates(subset=['product_name', 'match']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc9225",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4193a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b5c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae11162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e38d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3806e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
