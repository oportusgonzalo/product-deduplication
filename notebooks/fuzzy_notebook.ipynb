{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee9d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05930792",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c721dc",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c903970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "parent_chain = 'booker' # lower case and \"clean\"\n",
    "parent_chain_column = 'parent_chain_name'\n",
    "item_column = 'sku_name'\n",
    "language_ = 'en'\n",
    "threshold_ = 82\n",
    "parent_chain_use = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bcc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading raw data\n",
    "data = pd.read_csv('UK_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, col_name, new_col_name):\n",
    "    # column values to lower case\n",
    "    df[new_col_name] = df[col_name].str.lower().str.strip()\n",
    "    # removes special characters\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z.% \\t])\", \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dad2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parent_chain_use:\n",
    "    # cleaning parent chain name as it has duplicated entries\n",
    "    df = clean_text(data, parent_chain_column, '{}_{}'.format(parent_chain_column, 'norm'))\n",
    "    # chain selection and columns to work on\n",
    "    df_nlp = df[df['parent_chain_name_norm'] == parent_chain]\n",
    "    df_nlp = df_nlp.loc[:, ['parent_chain_name_norm', item_column]].reset_index(drop=True)\n",
    "else:\n",
    "    df_nlp = data.loc[:, [item_column]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item name standardization\n",
    "df_nlp.rename(columns={'sku_name': 'item_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baee2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial products: 4581\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial products: {len(list(set(df_nlp['item_name'].unique())))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63524601",
   "metadata": {},
   "source": [
    "## 2. NLP Aplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44817e50",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a procedure that let us synthesize natural language and speech. Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04de77",
   "metadata": {},
   "source": [
    "###  2.1 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbd80e",
   "metadata": {},
   "source": [
    "Remove noise so the computer can easier detect patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461615d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = clean_text(df_nlp, 'item_name', 'item_name_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4194789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4581, 4344)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing unique product names: pre-normalization vs post-normalization\n",
    "len(df_nlp.item_name.unique()), len(df_nlp.item_name_norm.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4b9d0",
   "metadata": {},
   "source": [
    "### 2.2 Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a24600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "if language_ == 'en':\n",
    "    stop_words = stopwords.words('english')\n",
    "elif language_ == 'es':\n",
    "    stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c74e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_stop_words(df, col, stop_list):\n",
    "    df['{}_stop'.format(col)] = df[col].apply(lambda x: ' '.join([word for word in x.split() if x not in stop_list]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9dfd476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = replace_stop_words(df_nlp, 'item_name_norm', stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c715d3",
   "metadata": {},
   "source": [
    "### 2.3 Phrase tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d96cac1",
   "metadata": {},
   "source": [
    "Tokenization refers to the process of splitting a phrase into a list, were each element of the list is a word of the phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b19389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d8a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['item_name_token'] = df_nlp['item_name_norm_stop'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54951275",
   "metadata": {},
   "source": [
    "### 2.4 Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9444f",
   "metadata": {},
   "source": [
    "Here we aim to reduce each tokenized word to their root form. If we do this, we will reduce the noise in the dataset. Need to be careful because in the process we can also introduce duplicates.\n",
    "\n",
    "Btw, the method used morphological analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95664dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a9a873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    text_lemma = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ff82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['item_name_token_lemma'] = df_nlp['item_name_token'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28ce65",
   "metadata": {},
   "source": [
    "### 2.5 Join Lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90733250",
   "metadata": {},
   "source": [
    "We join each word of the sku_token_lemma list, by row, to get the root text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b820ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['product_name'] = df_nlp['item_name_token_lemma'].apply(lambda list_: ' '.join([word for word in list_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4afa8c",
   "metadata": {},
   "source": [
    "### 2.6 Clean product names with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d493a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_clean = r'(pm \\d+\\w+)|(pm \\d+\\.\\d+)|(pm\\d+\\.\\d+)|(\\d+ pmp)|(pm\\d+)|( \\.+)|(pmp\\d+.\\d+)|(\\d+pmp)|(pmp \\d+)'\n",
    "\n",
    "df_nlp['product_name'] = df_nlp['product_name'].apply(lambda x: re.sub(regex_clean, \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26069f8",
   "metadata": {},
   "source": [
    "NOTE: \"df_nlp\" will be the connection between the product name iterations and further columns with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc2ed8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4581, 4291)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique items\n",
    "len(df_nlp.item_name.unique()), len(df_nlp.product_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079e7a5",
   "metadata": {},
   "source": [
    "## 3. Fuzzywuzzy Ratios Calculation & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8e1f8",
   "metadata": {},
   "source": [
    "In this step, we apply the fuzzywuzzy method \"token_sort_ratio\" to identify product names similarities. What's Fuzzywuzzy? --> library that uses Levenshtein Distance to calculate the differences between sequences and patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d06377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uselful columns selection (item selected just for 'product_name' not be treated as array)\n",
    "df_fuzzy = df_nlp.loc[:, ['product_name']]\n",
    "df_fuzzy = df_fuzzy.drop_duplicates('product_name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9394b67",
   "metadata": {},
   "source": [
    "QUIZAS PERMITE OPTIMIZAR SI HAGO UN MELT DEL CROSSTAB ANTES DE CALCULAR EL FUZZY RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d5ea8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_ratios(df, item_name, method):\n",
    "    \"\"\"\n",
    "    Calculates the fuzzy match between a set of products\n",
    "    Inputs:\n",
    "    - df: dataframe with all the data\n",
    "    - item_name: product name column\n",
    "    - method: fuzzywuzzy method to apply (ratio, partial_ratio, or sort_ratio)\n",
    "    \n",
    "    Returns a dataframe like: |product|match|fuzzy_ratio|\n",
    "    \"\"\"\n",
    "    df_temp = df.copy()\n",
    "    # fuzzy comparisson column\n",
    "    df_temp['match'] = df_temp[item_name]\n",
    "    # creating matrix\n",
    "    cross_tab = pd.crosstab(df_temp[item_name], df_temp['match'])\n",
    "    # calculating the fuzzy ratio between the product names\n",
    "    cross_tab = cross_tab.apply(lambda col: [method(col.name, x) for x in col.index])\n",
    "    # melting the matrix back to a pandas dataframe\n",
    "    fuzzy_df = cross_tab.reset_index().melt(id_vars=[item_name], value_name='fuzz_ratio')\n",
    "    # sort by: product name\n",
    "    fuzzy_df = fuzzy_df.sort_values(by=item_name).reset_index(drop=True)\n",
    "    return fuzzy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9ed49",
   "metadata": {},
   "source": [
    "### 3.1 Calculation similarity ratios betwen products --> fuzz.token_sort_ratio() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a668037",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy = fuzzy_ratios(df=df_fuzzy, item_name='product_name', method=fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d691611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18412681, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the result is a HUGE dataframe\n",
    "fuzzy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3cd69c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>match</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>milkybar 100g</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>casillero del diablo cab sau 75cl</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>skittle giant fruit sweet price marked bag 125g</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>calypso strawberry lemonade light 16oz 473ml</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_name                                            match  \\\n",
       "0  1.5 lt chardolini                                1.5 lt chardolini   \n",
       "1  1.5 lt chardolini                                   milkybar 100g    \n",
       "2  1.5 lt chardolini                casillero del diablo cab sau 75cl   \n",
       "3  1.5 lt chardolini  skittle giant fruit sweet price marked bag 125g   \n",
       "4  1.5 lt chardolini     calypso strawberry lemonade light 16oz 473ml   \n",
       "\n",
       "   fuzz_ratio  \n",
       "0         100  \n",
       "1          27  \n",
       "2          36  \n",
       "3          34  \n",
       "4          36  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd4ea5",
   "metadata": {},
   "source": [
    "### 3.2 Filtering matches by a similarity threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ab0ee",
   "metadata": {},
   "source": [
    "According to the literature, a threshold ratio of 80-85 for the fuzzy similarity ratio is a good filter. Below that means that the products don't share much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2609f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 82\n"
     ]
    }
   ],
   "source": [
    "print(f'Threshold: {threshold_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c48d934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data by the default threshold\n",
    "fuzzy_thl = fuzzy[fuzzy['fuzz_ratio'] > threshold_].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a405f041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11057, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the dataframe above calms our mind down\n",
    "fuzzy_thl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d57b54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of the table to join\n",
    "fuzzy_thl_copy = fuzzy_thl.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a80fbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting just to keep my head \"calm\"\n",
    "fuzzy_thl = fuzzy_thl.sort_values(by=['product_name', 'fuzz_ratio']).reset_index(drop=True)\n",
    "fuzzy_thl_copy = fuzzy_thl_copy.sort_values(by=['product_name', 'fuzz_ratio']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e133e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>match</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5ltr</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.75ltr</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.75</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100 g buttery flapjack</td>\n",
       "      <td>100 g buttery flapjack</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10pk carling can</td>\n",
       "      <td>10pk carling can</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "      <td>chicago town stuffed crust pepperoni pizza 490g</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  \\\n",
       "0                                  1.5 lt chardolini   \n",
       "1                                    1.75l coca cola   \n",
       "2                                    1.75l coca cola   \n",
       "3                                    1.75l coca cola   \n",
       "4                                    1.75l coca cola   \n",
       "5                                    1.75l coca cola   \n",
       "6                             100 g buttery flapjack   \n",
       "7                                   10pk carling can   \n",
       "8  12 inch hot chicago town stuffed crust pizza p...   \n",
       "9  12 inch hot chicago town stuffed crust pizza p...   \n",
       "\n",
       "                                               match  fuzz_ratio  \n",
       "0                                  1.5 lt chardolini         100  \n",
       "1                                  coca cola 1.5l 1.          90  \n",
       "2                                   coca cola 1.5ltr          90  \n",
       "3                                  coca cola 1.75ltr          94  \n",
       "4                                     coca cola 1.75          97  \n",
       "5                                    1.75l coca cola         100  \n",
       "6                             100 g buttery flapjack         100  \n",
       "7                                   10pk carling can         100  \n",
       "8    chicago town stuffed crust pepperoni pizza 490g          85  \n",
       "9  12 inch hot chicago town stuffed crust pizza p...         100  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_thl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e0fff",
   "metadata": {},
   "source": [
    "## 4. Extending product similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492689c",
   "metadata": {},
   "source": [
    "IDEA: Extend the products to which a product can be similar to. How? If product A is similar to B and C; and B is similar to F and G; and C is similar to A and D; then A must share relevant similarities with: B, C, D, F, and G."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884782a1",
   "metadata": {},
   "source": [
    "### 4.1 Pre-work: join between the same table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50bc7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to create have clarity of columns when merging\n",
    "fuzzy_thl_copy.rename(columns={'product_name': 'joined_by_match', 'match': 'extend_match', \\\n",
    "                               'fuzz_ratio': 'extend_fuzz_ratio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad21b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = fuzzy_thl.merge(fuzzy_thl_copy, left_on='match', right_on='joined_by_match', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6156dc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>match</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>joined_by_match</th>\n",
       "      <th>extend_match</th>\n",
       "      <th>extend_fuzz_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>90</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>coca cola 1.75ltr</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>90</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>coca cola 1.75</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>90</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>coca cola 1.5ltr</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>90</td>\n",
       "      <td>coca cola 1.5l 1.</td>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_name              match  fuzz_ratio    joined_by_match  \\\n",
       "0  1.5 lt chardolini  1.5 lt chardolini         100  1.5 lt chardolini   \n",
       "1    1.75l coca cola  coca cola 1.5l 1.          90  coca cola 1.5l 1.   \n",
       "2    1.75l coca cola  coca cola 1.5l 1.          90  coca cola 1.5l 1.   \n",
       "3    1.75l coca cola  coca cola 1.5l 1.          90  coca cola 1.5l 1.   \n",
       "4    1.75l coca cola  coca cola 1.5l 1.          90  coca cola 1.5l 1.   \n",
       "\n",
       "        extend_match  extend_fuzz_ratio  \n",
       "0  1.5 lt chardolini                100  \n",
       "1  coca cola 1.75ltr                 85  \n",
       "2     coca cola 1.75                 87  \n",
       "3   coca cola 1.5ltr                 88  \n",
       "4    1.75l coca cola                 90  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe687b77",
   "metadata": {},
   "source": [
    "### 4.2 Formatting the dataframe --> clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddba97e",
   "metadata": {},
   "source": [
    "The fuzzy ratio of the candidate can be interpretated like this:\n",
    "\n",
    "\"The candidate A fuzzy similarity ratio with a product C, that is similar to B, and B is directly related to A, is the mean between the similarity of A-B and B-C\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c284a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the extend_fuzz_ratio measure\n",
    "merged_df['extend_fuzz_ratio'] = merged_df[['fuzz_ratio', 'extend_fuzz_ratio']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb0de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicated column (equal to match)\n",
    "merged_df.drop('joined_by_match', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba52e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all similars to same column (extending in number of rows): match & extend_match --> match\n",
    "merged_df = merged_df.melt(id_vars=['product_name', 'fuzz_ratio', 'extend_fuzz_ratio'], value_name='candidate')\n",
    "merged_df = merged_df.sort_values(by='product_name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b2d7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the correct ratio if variable is 'match' or 'extend_match' --> melt issue\n",
    "merged_df['ratio'] = np.where(merged_df['variable'] == 'match', merged_df['fuzz_ratio'], \\\n",
    "                                                               merged_df['extend_fuzz_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fddcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping extra columns\n",
    "merged_df.drop(['fuzz_ratio', 'extend_fuzz_ratio'], axis=1, inplace=True)\n",
    "merged_df.rename(columns={'ratio': 'fuzz_ratio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1d7d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicated entries --> extend product is the same as the first match\n",
    "merged_df = merged_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e40bd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>variable</th>\n",
       "      <th>candidate</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>match</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>extend_match</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>extend_match</td>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>extend_match</td>\n",
       "      <td>coca cola 1.75ltr</td>\n",
       "      <td>93.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.75l coca cola</td>\n",
       "      <td>extend_match</td>\n",
       "      <td>coca cola 1.5ltr</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_name      variable          candidate  fuzz_ratio\n",
       "0  1.5 lt chardolini         match  1.5 lt chardolini       100.0\n",
       "1  1.5 lt chardolini  extend_match  1.5 lt chardolini       100.0\n",
       "2    1.75l coca cola  extend_match    1.75l coca cola        97.0\n",
       "3    1.75l coca cola  extend_match  coca cola 1.75ltr        93.5\n",
       "4    1.75l coca cola  extend_match   coca cola 1.5ltr        92.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76471c7",
   "metadata": {},
   "source": [
    "## 5. Identifying package similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc9225",
   "metadata": {},
   "source": [
    "A useful method to explore a deeper level of relatedness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dbf1e1",
   "metadata": {},
   "source": [
    "### 5.1 Regex to identify the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad75ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_extract(df, column, regex_):\n",
    "    \"\"\"\n",
    "    Extracts the package from a product name. Uses a regular expression for these.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: dataframe\n",
    "    - column: product name column where to look for packages\n",
    "    - regex_: regular expression formula to match patterns\n",
    "    \n",
    "    Output: a column with the package of the specified product name column\n",
    "    \"\"\"\n",
    "    packs = df[column].str.extract(regex_)\n",
    "    packs['package'] = packs[packs.columns[0:]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    packs = packs.loc[:, ['package']]\n",
    "    return packs.loc[:, ['package']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf838cd",
   "metadata": {},
   "source": [
    "NOTE: products like '7 up 500ml' have issues, or that contain 500ml or 500 ml (all products that end in ..0 something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3bcbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_package = r'(\\d+x\\d+\\w+)|(\\d+ x \\d+\\w+)|(\\d+\\.+\\d+\\w+)|(\\d+\\.+\\d+ \\w+)|(\\d+ ml)|(\\d+ g)|(\\d+\\w+)|(\\d+ \\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04ad3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group(group_df, regex_, threshold_=85):\n",
    "    \"\"\"\n",
    "    From a group of products which are similar, compares if they share the same/similar package. For this, uses \n",
    "    \"package_extract\" function to extract the package of the \"leader\" product, and its similars; and then uses\n",
    "    fuzzywuzzy to compare the similarity of the packages. Finally, keeps the packages with similarity over a threshold\n",
    "    of 75 or the one specified by the user.\n",
    "    \n",
    "    Inputs:\n",
    "    - group_df: dataframe with a group of similar products\n",
    "    - regex_: regex formula to extract the package\n",
    "    - threshold_: threshold of similarity to compare package\n",
    "    \n",
    "    Output: a clean group of similar candidates\n",
    "    \"\"\"\n",
    "    group_df['package'] = package_extract(group_df, 'product_name', regex_)\n",
    "    group_df['package_candidate'] = package_extract(group_df, 'candidate', regex_)\n",
    "    group_df['package_ratio'] = group_df.apply(lambda x: fuzz.token_sort_ratio(x['package'], x['package_candidate']), axis=1)\n",
    "    group_df = group_df[group_df['package_ratio'] >= threshold_].copy()\n",
    "    group_df = group_df.loc[:, ['product_name', 'candidate', 'fuzz_ratio']]\n",
    "    group_df.reset_index(drop=True, inplace=True)\n",
    "    return group_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe688c",
   "metadata": {},
   "source": [
    "## 6. Identifying groups of products with high similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c05f04",
   "metadata": {},
   "source": [
    "Idea: get groups of products that might be the same product (high similarity). Important to verify if the products are duplicated into more than a group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587197c7",
   "metadata": {},
   "source": [
    "Steps:\n",
    "    \n",
    "* Identify the product group\n",
    "* Keep in the group products with similar package (fuzzy)\n",
    "* Get every group candidate\n",
    "* For each candidate:\n",
    "    * Verify if is part of a group\n",
    "    * Yes: concat all the products and re-create the group; remove the group from the catalog_df\n",
    "    * No: keep the group as it is\n",
    "    * Once finished for all, add the group with new ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ae5cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_selection(df, product):\n",
    "    \"\"\"\n",
    "    Por a single product, identifies the products to which is related (all products in \"candidate\" column), and\n",
    "    remove duplicated rows. The ratio is also included to keep the knowledge of the similarity ratio that let \n",
    "    them into the group.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: dataframe with threshold 80, with all matches and links (for all products)\n",
    "    - product: the name of the product to work with\n",
    "    \n",
    "    Output: single product similarity group dataframe\n",
    "    \"\"\"\n",
    "    # we select all the rows that match the product\n",
    "    df_temp = df[df['product_name'] == product].copy()\n",
    "    # remove duplicates: to see all the products to which a product is similar\n",
    "    group = df_temp.drop_duplicates(subset=['product_name', 'candidate']).reset_index(drop=True)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d247082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_df(groups_df, product, product_group_list):\n",
    "    \n",
    "    if groups_df.shape[0] == 0:\n",
    "        group_id = 0\n",
    "    else:\n",
    "        group_id = groups_df['group_id'].max() + 1\n",
    "    df_temp = pd.DataFrame({\n",
    "        'group_id': group_id,\n",
    "        'leader': product,\n",
    "        'member': product_group_list\n",
    "        })\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e708cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_track_temp_df(track_df, applicants_list):\n",
    "    if track_df.shape[0] == 0:\n",
    "        group_id = 0\n",
    "    else:\n",
    "        group_id = track_df['group_id'].max() + 1\n",
    "    df_temp = pd.DataFrame({\n",
    "        'group_id': group_id,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08797094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_concat_procedure(groups_df, track_df, product_, applicants_list):\n",
    "    # verify if any of the applicants is already assigned to a group, if not:\n",
    "    if track_df[track_df['member'].isin(applicants_list)].shape[0] == 0:\n",
    "        # create df for the group\n",
    "        concat_df = create_product_df(groups_df, product_, applicants_list)\n",
    "        # concat to the global groups df\n",
    "        groups_df = pd.concat([groups_df, concat_df], axis=0).reset_index(drop=True)\n",
    "        # create track applicants df\n",
    "        df_track_temp = create_track_temp_df(track_df, applicants_list)\n",
    "        # concat new group to track groups df\n",
    "        track_df = pd.concat([track_df, df_track_temp], axis=0).reset_index(drop=True)\n",
    "    else:\n",
    "        # get the group ids where any of the candidates is assigned\n",
    "        group_ids_list = list(track_df[track_df['member'].isin(applicants_list)]['group_id'].unique())\n",
    "        # locate where the group is\n",
    "        select_df = groups_df[groups_df['group_id'].isin(group_ids_list)]\n",
    "        # list of actual members of the group\n",
    "        already_members = list(pd.unique(select_df[['leader', 'member']].values.ravel('K')))\n",
    "        # union of already members + apliccants list --> idea: get a unique selection of a wider spectrum\n",
    "        concatenated_list = list(set(already_members + applicants_list))\n",
    "        # remove group from global groups dataframe\n",
    "        groups_df = groups_df[~groups_df['group_id'].isin(group_ids_list)].copy()\n",
    "        # remove group from track groups dataframe\n",
    "        track_df = track_df[~track_df['group_id'].isin(group_ids_list)]\n",
    "        # re-create and add the modified group to the global groups df\n",
    "        concat_df = create_product_df(groups_df, product_, concatenated_list)\n",
    "        groups_df = pd.concat([groups_df, concat_df], axis=0).reset_index(drop=True)\n",
    "        # re-create and add the modified group to the track groups df\n",
    "        df_track_temp = create_track_temp_df(track_df, applicants_list)\n",
    "        track_df = pd.concat([track_df, df_track_temp], axis=0).reset_index(drop=True)\n",
    "    return groups_df, track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67b60de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop('variable', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91874be5",
   "metadata": {},
   "source": [
    "### 6.1 Selecting the similarity group of a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8b93fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe definition\n",
    "groups_df = pd.DataFrame(columns=['group_id', 'leader', 'member'])\n",
    "track_df = pd.DataFrame(columns=['group_id', 'member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8315681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all products \n",
    "products_list = merged_df['product_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ef0e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_ in products_list:\n",
    "    # select the group of similars to product_\n",
    "    candidate_group = group_selection(merged_df, product_)\n",
    "    # remove products without package similarity (fuzzy: threshold specified)\n",
    "    clean_candidate_group = clean_group(candidate_group, reg_package, threshold_=85)\n",
    "    # get all the products in the applicant group\n",
    "    applicants_list = list(pd.unique(clean_candidate_group[['product_name', 'candidate']].values.ravel('K')))\n",
    "    # integration to global groups df\n",
    "    groups_df, track_df = group_concat_procedure(groups_df, track_df, product_, applicants_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c55cd370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>leader</th>\n",
       "      <th>member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100 g buttery flapjack</td>\n",
       "      <td>100 g buttery flapjack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10pk carling can</td>\n",
       "      <td>10pk carling can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 pizza meal deal</td>\n",
       "      <td>12 pizza meal deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>3818</td>\n",
       "      <td>young admiral pie 300g</td>\n",
       "      <td>young admiral pie 300g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>3819</td>\n",
       "      <td>yp pea spinach soup 600g</td>\n",
       "      <td>yp pea spinach soup 600g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>3820</td>\n",
       "      <td>zoflora 3in1 disinfectant 120ml</td>\n",
       "      <td>zoflora 3in1 disinfectant 120ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>3821</td>\n",
       "      <td>zyweic 4 pack</td>\n",
       "      <td>zyweic 4 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>3822</td>\n",
       "      <td>zywiec 1856 polish 4x500ml</td>\n",
       "      <td>zywiec 1856 polish 4x500ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4311 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     group_id                                             leader  \\\n",
       "0           0                                  1.5 lt chardolini   \n",
       "1           2                             100 g buttery flapjack   \n",
       "2           3                                   10pk carling can   \n",
       "3           4  12 inch hot chicago town stuffed crust pizza p...   \n",
       "4           5                                 12 pizza meal deal   \n",
       "...       ...                                                ...   \n",
       "4306     3818                             young admiral pie 300g   \n",
       "4307     3819                           yp pea spinach soup 600g   \n",
       "4308     3820                    zoflora 3in1 disinfectant 120ml   \n",
       "4309     3821                                      zyweic 4 pack   \n",
       "4310     3822                         zywiec 1856 polish 4x500ml   \n",
       "\n",
       "                                                 member  \n",
       "0                                     1.5 lt chardolini  \n",
       "1                                100 g buttery flapjack  \n",
       "2                                      10pk carling can  \n",
       "3     12 inch hot chicago town stuffed crust pizza p...  \n",
       "4                                    12 pizza meal deal  \n",
       "...                                                 ...  \n",
       "4306                             young admiral pie 300g  \n",
       "4307                           yp pea spinach soup 600g  \n",
       "4308                    zoflora 3in1 disinfectant 120ml  \n",
       "4309                                      zyweic 4 pack  \n",
       "4310                         zywiec 1856 polish 4x500ml  \n",
       "\n",
       "[4311 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7934bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>member</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5 lt chardolini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100 g buttery flapjack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10pk carling can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12 inch hot chicago town stuffed crust pizza p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 pizza meal deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>3818</td>\n",
       "      <td>young admiral pie 300g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>3819</td>\n",
       "      <td>yp pea spinach soup 600g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>3820</td>\n",
       "      <td>zoflora 3in1 disinfectant 120ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>3821</td>\n",
       "      <td>zyweic 4 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>3822</td>\n",
       "      <td>zywiec 1856 polish 4x500ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4147 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     group_id                                             member\n",
       "0           0                                  1.5 lt chardolini\n",
       "1           2                             100 g buttery flapjack\n",
       "2           3                                   10pk carling can\n",
       "3           4  12 inch hot chicago town stuffed crust pizza p...\n",
       "4           5                                 12 pizza meal deal\n",
       "...       ...                                                ...\n",
       "4142     3818                             young admiral pie 300g\n",
       "4143     3819                           yp pea spinach soup 600g\n",
       "4144     3820                    zoflora 3in1 disinfectant 120ml\n",
       "4145     3821                                      zyweic 4 pack\n",
       "4146     3822                         zywiec 1856 polish 4x500ml\n",
       "\n",
       "[4147 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bcb0f",
   "metadata": {},
   "source": [
    "## 9. Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ef9b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.to_csv('product_groups_{}.csv'.format(threshold_), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e38d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3806e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
