{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee9d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein as lev\n",
    "from fuzzywuzzy import fuzz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05930792",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c721dc",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c903970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "parent_chain = 'booker' # lower case and \"clean\"\n",
    "parent_chain_column = 'parent_chain_name'\n",
    "item_column = 'item_name'\n",
    "language_ = 'en'\n",
    "threshold_ = 82\n",
    "parent_chain_use = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bcc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading raw data\n",
    "data = pd.read_csv('uk_booker_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, col_name, new_col_name):\n",
    "    # column values to lower case\n",
    "    df[new_col_name] = df[col_name].str.lower().str.strip()\n",
    "    # removes special characters\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z.% \\t])\", \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dad2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parent_chain_use:\n",
    "    # cleaning parent chain name as it has duplicated entries\n",
    "    df = clean_text(data, parent_chain_column, '{}_{}'.format(parent_chain_column, 'norm'))\n",
    "    # chain selection and columns to work on\n",
    "    df_nlp = df[df['parent_chain_name_norm'] == parent_chain]\n",
    "    df_nlp = df_nlp.loc[:, ['parent_chain_name_norm', item_column]].reset_index(drop=True)\n",
    "else:\n",
    "    df_nlp = data.loc[:, [item_column]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item name standardization\n",
    "df_nlp.rename(columns={'sku_name': 'item_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baee2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial products: 50587\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial products: {len(list(set(df_nlp['item_name'].unique())))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63524601",
   "metadata": {},
   "source": [
    "## 2. NLP Aplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7135eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language_ == 'en':\n",
    "    stop_words = stopwords.words('english')\n",
    "elif language_ == 'es':\n",
    "    stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_stop_words(df, col, stop_list):\n",
    "    df['{}_stop'.format(col)] = df[col].apply(lambda x: ' '.join([word for word in x.split() if x not in stop_list]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2097f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    text_lemma = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_clean = r'(pm \\d+\\w+)|(pm \\d+\\.\\d+)|(pm\\d+\\.\\d+)|(\\d+ pmp)|(pm\\d+)|( \\.+)|(pmp\\d+.\\d+)|(\\d+pmp)|(pmp \\d+)|(\\d+.\\d+ pm)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80062c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cleaning(df, stop_words, regex_clean):\n",
    "    # normalization\n",
    "    df = clean_text(df, 'item_name', 'item_name_norm')\n",
    "    # remove stop words\n",
    "    df = replace_stop_words(df, 'item_name_norm', stop_words)\n",
    "    # tokenize text\n",
    "    df['item_name_token'] = df['item_name_norm_stop'].apply(lambda x: word_tokenize(x))\n",
    "    # lemmatization\n",
    "    df['item_name_token_lemma'] = df['item_name_token'].apply(lambda x: word_lemmatizer(x))\n",
    "    # joining lemmas\n",
    "    df['product_name'] = df['item_name_token_lemma'].apply(lambda list_: ' '.join([word for word in list_]))\n",
    "    # cleaning product names with regex\n",
    "    df['product_name'] = df['product_name'].apply(lambda x: re.sub(regex_clean, \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3998754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = nlp_cleaning(df_nlp, stop_words, regex_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique items\n",
    "len(df_nlp.item_name.unique()), len(df_nlp.product_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60899ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079e7a5",
   "metadata": {},
   "source": [
    "## 3. Levenshtein Ratio Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e065157",
   "metadata": {},
   "source": [
    "### 3.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d06377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uselful columns selection (item selected just for 'product_name' not be treated as array)\n",
    "df_lev = df_nlp.loc[:, ['product_name']]\n",
    "df_lev = df_lev.drop_duplicates('product_name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b072329b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aunt bessies hearty homely dumpling mix 140g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc choc fudge brownie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batchelors big super noodle chicken flavour 100g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batchelors condensed soup cream of chicken 295g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batchelors cream of tomato condensed soup 295g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_name\n",
       "0      aunt bessies hearty homely dumpling mix 140g\n",
       "1                             bc choc fudge brownie\n",
       "2  batchelors big super noodle chicken flavour 100g\n",
       "3   batchelors condensed soup cream of chicken 295g\n",
       "4    batchelors cream of tomato condensed soup 295g"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "219b8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ = df_lev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42a2e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix creation --> null values\n",
    "matrix_ = np.zeros((len_, len_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef078691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41819, 41819)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f52e43",
   "metadata": {},
   "source": [
    "### 3.2 Applying Levenshtein Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fd7baae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1659027592.2706292"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db1abda0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, product_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_lev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_name\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, match_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_lev[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_name\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 3\u001b[0m         matrix_[i][j] \u001b[38;5;241m=\u001b[39m \u001b[43mfuzz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_sort_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:105\u001b[0m, in \u001b[0;36mtoken_sort_ratio\u001b[0;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoken_sort_ratio\u001b[39m(s1, s2, force_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, full_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a measure of the sequences' similarity between 0 and 100\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    but sorting the token before comparing.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_token_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/fuzzywuzzy/utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:92\u001b[0m, in \u001b[0;36m_token_sort\u001b[0;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_none\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_token_sort\u001b[39m(s1, s2, partial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, full_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 92\u001b[0m     sorted1 \u001b[38;5;241m=\u001b[39m \u001b[43m_process_and_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     sorted2 \u001b[38;5;241m=\u001b[39m _process_and_sort(s2, force_ascii, full_process\u001b[38;5;241m=\u001b[39mfull_process)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:78\u001b[0m, in \u001b[0;36m_process_and_sort\u001b[0;34m(s, force_ascii, full_process)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"Return a cleaned string with token sorted.\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# pull tokens\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m full_process \u001b[38;5;28;01melse\u001b[39;00m s\n\u001b[1;32m     79\u001b[0m tokens \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# sort tokens and join\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/fuzzywuzzy/utils.py:95\u001b[0m, in \u001b[0;36mfull_process\u001b[0;34m(s, force_ascii)\u001b[0m\n\u001b[1;32m     93\u001b[0m     s \u001b[38;5;241m=\u001b[39m asciidammit(s)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Keep only Letters and Numbers (see Unicode docs).\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m string_out \u001b[38;5;241m=\u001b[39m \u001b[43mStringProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_non_letters_non_numbers_with_whitespace\u001b[49m(s)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Force into lowercase.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m string_out \u001b[38;5;241m=\u001b[39m StringProcessor\u001b[38;5;241m.\u001b[39mto_lower_case(string_out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, product_ in enumerate(df_lev['product_name']):\n",
    "    for j, match_ in enumerate(df_lev['product_name']):\n",
    "        matrix_[i][j] = fuzz.token_sort_ratio(match_, product_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()-t1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aea58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Direct Levenshtein for 50K: {t/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix copy\n",
    "matrix_copy = matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e319a35",
   "metadata": {},
   "source": [
    "### 4. Matrix to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6c464",
   "metadata": {},
   "source": [
    "IDEA:\n",
    "\n",
    "* podria hacer un diccionario entre: product-index\n",
    "* por cada producto, tomo su fila\n",
    "* filtro por el threshold\n",
    "* traigo los similares de los matches actuales usando su index\n",
    "* integro al dataframe bajo condiciones ya establecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_list = list(df_lev['product_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with lev ratios\n",
    "df_ratios = pd.DataFrame(matrix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d247082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group_track_df(groups_df, track_df, product, applicants_list):\n",
    "    if groups_df.shape[0] == 0:\n",
    "        group_id = 0\n",
    "    else:\n",
    "        group_id = groups_df['group_id'].max() + 1\n",
    "    if track_df.shape[0] == 0:\n",
    "        track_id = 0\n",
    "    else:\n",
    "        track_id = track_df['group_id'].max() + 1\n",
    "        \n",
    "    df_temp_group = pd.DataFrame({\n",
    "        'group_id': group_id,\n",
    "        'leader': product,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    df_temp_track = pd.DataFrame({\n",
    "        'group_id': track_id,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    \n",
    "    return df_temp_group, df_temp_track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c838de8",
   "metadata": {},
   "source": [
    "### Package similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea735141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_extract(df, column, regex_):\n",
    "    \"\"\"\n",
    "    Extracts the package from a product name. Uses a regular expression for these.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: dataframe\n",
    "    - column: product name column where to look for packages\n",
    "    - regex_: regular expression formula to match patterns\n",
    "    \n",
    "    Output: a column with the package of the specified product name column\n",
    "    \"\"\"\n",
    "    packs = df[column].str.extract(regex_)\n",
    "    packs['package'] = packs[packs.columns[0:]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    packs = packs.loc[:, ['package']]\n",
    "    return packs.loc[:, ['package']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0874d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_package = r'(\\d+x\\d+\\w+)|(\\d+ x \\d+\\w+)|(\\d+\\.+\\d+\\w+)|(\\d+\\.+\\d+ \\w+)|(\\d+ ml)|(\\d+ g)|(\\d+\\w+)|(\\d+ \\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_group(group_df, regex_, threshold_=85):\n",
    "    \"\"\"\n",
    "    From a group of products which are similar, compares if they share the same/similar package. For this, uses \n",
    "    \"package_extract\" function to extract the package of the \"leader\" product, and its similars; and then uses\n",
    "    fuzzywuzzy to compare the similarity of the packages. Finally, keeps the packages with similarity over a threshold\n",
    "    of 75 or the one specified by the user.\n",
    "    \n",
    "    Inputs:\n",
    "    - group_df: dataframe with a group of similar products\n",
    "    - regex_: regex formula to extract the package\n",
    "    - threshold_: threshold of similarity to compare package\n",
    "    \n",
    "    Output: a clean group of similar candidates\n",
    "    \"\"\"\n",
    "    group_df['package'] = package_extract(group_df, 'product_name', regex_)\n",
    "    group_df['package_match'] = package_extract(group_df, 'match', regex_)\n",
    "    group_df['package_ratio'] = group_df.apply(lambda x: fuzz.token_sort_ratio(x['package'], x['package_match']), axis=1)\n",
    "    group_df = group_df[group_df['package_ratio'] >= threshold_].copy()\n",
    "    group_df = group_df.loc[:, ['product_name', 'match', 'lev_ratio']]\n",
    "    group_df.reset_index(drop=True, inplace=True)\n",
    "    return group_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb18b1",
   "metadata": {},
   "source": [
    "### 5. Identifying groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_concat_groups(groups_df, track_df, index_, applicants_list):\n",
    "    # verify if any of the applicants is already assigned to a group, if not:    \n",
    "    if track_df[track_df['member'].isin(applicants_list)].shape[0] == 0:\n",
    "        # create df for the group\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, applicants_list)\n",
    "        # concat group to the global groups df\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        # concat track group to track global groups df\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    else:\n",
    "        # get the group ids where all of the candidates are assigned\n",
    "        groups_id_list = list(track_df[track_df['member'].isin(applicants_list)]['group_id'].unique())\n",
    "        # locate where the group is\n",
    "        select_df = groups_df[groups_df['group_id'].isin(groups_id_list)]\n",
    "        # list of actual members of the group\n",
    "        already_members = list(pd.unique(select_df[['leader', 'member']].values.ravel('K')))\n",
    "        # union of already members + apliccants list --> idea: get a unique selection of a wider spectrum\n",
    "        concatenated_list = list(set(already_members + applicants_list))\n",
    "        # remove group from global groups and track dataframes\n",
    "        groups_df = groups_df[~groups_df['group_id'].isin(groups_id_list)].copy()\n",
    "        track_df = track_df[~track_df['group_id'].isin(groups_id_list)]\n",
    "        # re-create both: groups & track - global dfs\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, concatenated_list)\n",
    "        # add the new set to both: groups & track - global dfs\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    return groups_df, track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40986d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to match product names with index\n",
    "product_index_dict = dict(zip(product_name_list, df_ratios.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to match indexes with product_names\n",
    "index_product_dict = dict(zip(df_ratios.columns, product_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time before\n",
    "t_bef_group = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e03395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ce75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe definition\n",
    "groups_df = pd.DataFrame(columns=['group_id', 'leader', 'member'])\n",
    "track_df = pd.DataFrame(columns=['group_id', 'member'])\n",
    "\n",
    "# iterating for all products and defining final groups\n",
    "for product_, index_ in product_index_dict.items():\n",
    "    try:\n",
    "        # gets all levenshtein ratios of the product and the set\n",
    "        df_values = df_ratios.iloc[index_, :]\n",
    "        # we get the indexes of the products that have similarity measure over the threshold\n",
    "        similar_indexes_list = list(np.where(df_values > 0.8)[0])\n",
    "        # get the selection of products that are similar (extended) and also their levenshtein ratios\n",
    "        df_extended = df_ratios.iloc[similar_indexes_list, :]\n",
    "        # adds product name column to melt\n",
    "        df_extended.insert(0, 'product_name', df_extended.index)\n",
    "        # melt dataframe\n",
    "        df_melt = df_extended.melt(id_vars='product_name', var_name='match', value_name='lev_ratio')\n",
    "        # filter product lev ratios by threshold         \n",
    "        df_group = df_melt[df_melt['lev_ratio'] > 0.8].reset_index(drop=True)\n",
    "        # replacing product name to clarify the direction of similarities (product tha's being processed)\n",
    "        df_group['product_name'] = index_\n",
    "        \n",
    "        # cleaning group by applying package comparison (regex)\n",
    "        df_group['product_name'] = df_group['product_name'].map(index_product_dict)\n",
    "        df_group['match'] = df_group['match'].map(index_product_dict)\n",
    "        df_clean_group = clean_group(df_group, reg_package, threshold_=85)\n",
    "        # place back int values for better performance\n",
    "        df_clean_group['product_name'] = df_clean_group['product_name'].map(product_index_dict)\n",
    "        df_clean_group['match'] = df_clean_group['match'].map(product_index_dict)\n",
    "        \n",
    "        # removing duplicates (matches)\n",
    "        df_clean_group = df_clean_group.drop_duplicates(subset=['product_name', 'match']).reset_index(drop=True)\n",
    "        # applicants list (all products - including \"leader\")\n",
    "        applicants_list = list(pd.unique(df_clean_group[['product_name', 'match']].values.ravel('K')))\n",
    "        groups_df, track_df = verify_and_concat_groups(groups_df, track_df, index_, applicants_list)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(f'Failed product: {product_}; Index: {index_}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to run\n",
    "t_run = time.time()-t_bef_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d72bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time to run: {round(t_run/60, 2)} minutes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f31b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3db1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220b660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6694342",
   "metadata": {},
   "source": [
    "### 6. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe977f",
   "metadata": {},
   "source": [
    "#### 6.1 Verify if any leader leads more than 1 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_df = groups_df.loc[:, ['group_id', 'leader']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders_df[leaders_df['leader'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b57f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if leaders_df[leaders_df['leader'].duplicated() == True].shape[0] == 0:\n",
    "    print('Leaders lead correctly!')\n",
    "else:\n",
    "    print('Verify leaders please! They are repeated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd31f4",
   "metadata": {},
   "source": [
    "#### 6.2 Verify if any product belongs to more than 1 group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df = groups_df.loc[:, ['group_id', 'member']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df[members_df['member'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "if members_df[members_df['member'].duplicated() == True].shape[0] == 0:\n",
    "    print('Members are assigned correctly!')\n",
    "else:\n",
    "    print('Verify members please! Some are assigned to more than 1 group!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a4957",
   "metadata": {},
   "source": [
    "#### 6.3 All products have been assigned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee27041",
   "metadata": {},
   "source": [
    "Hipotesis:\n",
    "    \n",
    "* Se estan filtrando en el threshold, no tienen similares\n",
    "\n",
    "Confirmado:\n",
    "* No se estan agregando grupos!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19aaeb9",
   "metadata": {},
   "source": [
    "##### on groups DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652794e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_list = list(index_product_dict.keys())\n",
    "all_products_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a331fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_assigned_products = pd.unique(groups_df[['leader', 'member']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_groups = []\n",
    "for i in all_products_list:\n",
    "    if i not in groups_assigned_products:\n",
    "        not_in_groups.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83dbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products not assigned in groups_df: {len(not_in_groups)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc2e9f",
   "metadata": {},
   "source": [
    "##### On track DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_assigned_products = pd.unique(track_df[['group_id', 'member']].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_track = []\n",
    "for i in all_products_list:\n",
    "    if i not in track_assigned_products:\n",
    "        not_in_track.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f43f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products not assigned in track_df: {len(not_in_track)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1b6a2",
   "metadata": {},
   "source": [
    "##### Why not assigned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dab4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice_ in not_in_groups[:5]:\n",
    "    print(f'{indice_}: {index_product_dict[indice_]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice_ in not_in_track[:5]:\n",
    "    print(f'{indice_}: {index_product_dict[indice_]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32a2f4",
   "metadata": {},
   "source": [
    "### 7. Visualizing groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of unique groups: {len(groups_df[\"group_id\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b0fa9",
   "metadata": {},
   "source": [
    "#### 7.1 Replacing int product names with the actual name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caee19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df['leader'] = groups_df['leader'].map(index_product_dict)\n",
    "groups_df['member'] = groups_df['member'].map(index_product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = groups_df.sort_values(by=['leader', 'member']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163528f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d797249",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf4d36",
   "metadata": {},
   "source": [
    "##### Coca DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_df = groups_df[(groups_df['leader'].str.contains('coca'))|(groups_df['member'].str.contains('coca'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_df[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c542c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868d63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45609212",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a997a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbf474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0ae6ac8",
   "metadata": {},
   "source": [
    "### Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035fb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all levenshtein ratios of the product and the set\n",
    "df_values = df_ratios.iloc[100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the indexes of the products that have similarity measure over the threshold\n",
    "similar_indexes_list = list(np.where(df_values > 0.8)[0])\n",
    "similar_indexes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the selection of products that are similar (extended) and also their levenshtein ratios\n",
    "df_extended = df_ratios.iloc[similar_indexes_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds product name column to melt\n",
    "df_extended.insert(0, 'product_name', df_extended.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt dataframe\n",
    "df_melt = df_extended.melt(id_vars='product_name', var_name='match', value_name='lev_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aa37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter product lev ratios by threshold\n",
    "df_group = df_melt[df_melt['lev_ratio'] > 0.8].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing product name to clarify the direction of similarities (product tha's being processed)\n",
    "df_group['product_name'] = index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b367b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates (matches)\n",
    "df_clean_group = df_group.drop_duplicates(subset=['product_name', 'match']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc9225",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda07ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a78b2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c8c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e38d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3806e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
