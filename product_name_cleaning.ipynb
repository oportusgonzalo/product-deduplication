{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1ee9d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Levenshtein as lev\n",
    "from fuzzywuzzy import fuzz\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# To calculate: TF-IDF & Cosine Similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "25d5e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gonzalooportus/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05930792",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2870cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial time\n",
    "t_initial = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c721dc",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c903970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "country = 'cr'\n",
    "parent_chain = 'booker' # lower case and \"clean\"\n",
    "parent_chain_column = 'parent_chain_name'\n",
    "item_column = 'sku_name'\n",
    "language_ = 'es'\n",
    "threshold_products = 85\n",
    "threshold_package = 75\n",
    "parent_chain_use = False\n",
    "# to fix top in get_matches_df function\n",
    "stop_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "02bcc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading raw data\n",
    "data = pd.read_csv('data/CR_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c49f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, col_name, new_col_name):\n",
    "    # column values to lower case\n",
    "    df[new_col_name] = df[col_name].str.lower().str.strip()\n",
    "    # removes special characters\n",
    "    df[new_col_name] = df[new_col_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z.% \\t])\", \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6dad2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parent_chain_use:\n",
    "    # cleaning parent chain name as it has duplicated entries\n",
    "    df = clean_text(data, parent_chain_column, '{}_{}'.format(parent_chain_column, 'norm'))\n",
    "    # chain selection and columns to work on\n",
    "    df_nlp = df[df['parent_chain_name_norm'] == parent_chain]\n",
    "    df_nlp = df_nlp.loc[:, ['parent_chain_name_norm', item_column]].reset_index(drop=True)\n",
    "else:\n",
    "    df_nlp = data.loc[:, [item_column]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3bd1a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item name standardization\n",
    "df_nlp.rename(columns={'sku_name': 'item_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "baee2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial products: 2782\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial products: {len(list(set(df_nlp['item_name'].unique())))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63524601",
   "metadata": {},
   "source": [
    "## 2. NLP Aplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "185780a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language_ == 'en':\n",
    "    stop_words = stopwords.words('english')\n",
    "elif language_ == 'es':\n",
    "    stop_words = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ebc61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_stop_words(df, col, stop_list):\n",
    "    df['{}_stop'.format(col)] = df[col].apply(lambda x: ' '.join([word for word in x.split() if x not in stop_list]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c9038993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    text_lemma = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "66abde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_clean = r'(pm \\d+\\w+)|(pm \\d+\\.\\d+)|(pm\\d+\\.\\d+)|(\\d+ pmp)|(pm\\d+)|( \\.+)|(pmp\\d+.\\d+)|(\\d+pmp)|(pmp \\d+)|(\\d+.\\d+ pm)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e733a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cleaning(df, stop_words, regex_clean):\n",
    "    # normalization\n",
    "    df = clean_text(df, 'item_name', 'item_name_norm')\n",
    "    # remove stop words\n",
    "    df = replace_stop_words(df, 'item_name_norm', stop_words)\n",
    "    # tokenize text\n",
    "    df['item_name_token'] = df['item_name_norm_stop'].apply(lambda x: word_tokenize(x))\n",
    "    # lemmatization\n",
    "    df['item_name_token_lemma'] = df['item_name_token'].apply(lambda x: word_lemmatizer(x))\n",
    "    # joining lemmas\n",
    "    df['product_name'] = df['item_name_token_lemma'].apply(lambda list_: ' '.join([word for word in list_]))\n",
    "    # cleaning product names with regex\n",
    "    df['product_name'] = df['product_name'].apply(lambda x: re.sub(regex_clean, \"\", x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5f179847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = nlp_cleaning(df_nlp, stop_words, regex_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique items\n",
    "len(df_nlp.item_name.unique()), len(df_nlp.product_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69989f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293c892",
   "metadata": {},
   "source": [
    "### Creating mapping between source item_name & product_name (post NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fcbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back_propagation = df_nlp.loc[:, ['item_name', 'product_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06831268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back_propagation.to_csv(f'back_propagation/groups_{country}_back_propagation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7da2e5",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee8f7b7",
   "metadata": {},
   "source": [
    "### Creating a tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing set for TF-IDF\n",
    "df_tf = df_nlp.loc[:, ['product_name']]\n",
    "df_tf = df_tf.drop_duplicates().reset_index(drop=True)\n",
    "df_tf['id'] = range(1, len(df_tf) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=2, token_pattern='(\\S+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53866e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tf-idf values\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(df_tf['product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862f4f9",
   "metadata": {},
   "source": [
    "## 4. Computing cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a04b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a compressed sparse row (CSR) matrix.\n",
    "    # CSR --> efficient operations, fast matrix vector products\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    \n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bddfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = cosine_similarity(tf_idf_matrix, tf_idf_matrix.transpose(), 25, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c784f93",
   "metadata": {},
   "source": [
    "### Create a match table to show the similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'product_name': left_side,\n",
    "                          'match': right_side,\n",
    "                           'similarity_score': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, df_tf['product_name'], top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f378ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = matches_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf6136",
   "metadata": {},
   "source": [
    "### Products without a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = list(df_tf.product_name.unique())\n",
    "match_list = list(pd.unique(matches_df[['product_name', 'match']].values.ravel('K')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a88414",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_match = []\n",
    "for prod_ in prod_list:\n",
    "    if prod_ not in match_list:\n",
    "        not_match.append(prod_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products without match: {len(not_match)}')\n",
    "print(f'Percentage of products without match: {round(len(not_match)/len(prod_list), 6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1da8db",
   "metadata": {},
   "source": [
    "### Who are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_match[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb597e41",
   "metadata": {},
   "source": [
    "## 5. Grouping products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d37335",
   "metadata": {},
   "source": [
    "### 5.1 Fuzzy ratios calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72588a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df['fuzz_ratio'] = matches_df.apply(lambda x: fuzz.token_sort_ratio(x['product_name'], x['match']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f46ebc",
   "metadata": {},
   "source": [
    "### 5.2 Splitting matches with high-low fuzzy ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Product Threshold: {threshold_products}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars = matches_df[matches_df['fuzz_ratio'] >= threshold_products].\\\n",
    "                        drop_duplicates(subset=['product_name', 'match']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76a450",
   "metadata": {},
   "source": [
    "### 5.3 Logic to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ecedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars = df_similars.sort_values(by=['product_name', 'match']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2441b4",
   "metadata": {},
   "source": [
    "### a) Extending similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7392523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_copy = df_similars.drop(columns=['similarity_score', 'fuzz_ratio'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be143efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_copy.rename(columns={'match': 'extended_match', 'product_name': 'match'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending\n",
    "df_similars_mrg = df_similars.merge(df_similars_copy, how='inner', on='match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31966e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_mrg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_mrg.drop('similarity_score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83aa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt dataframe\n",
    "df_melt = df_similars_mrg.melt(id_vars=['product_name', 'fuzz_ratio'], var_name='which_match', value_name='candidate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = df_melt.drop('which_match', axis=1)[['product_name', 'candidate', 'fuzz_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f82911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_ext = df_melt.drop_duplicates(['product_name', 'candidate']).sort_values(by=['product_name', 'candidate'])\\\n",
    "            .reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56e4d3",
   "metadata": {},
   "source": [
    "### b) Package similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_extract(df, column, regex_):\n",
    "    \"\"\"\n",
    "    Extracts the package from a product name. Uses a regular expression for these.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: dataframe\n",
    "    - column: product name column where to look for packages\n",
    "    - regex_: regular expression formula to match patterns\n",
    "    \n",
    "    Output: a column with the package of the specified product name column\n",
    "    \"\"\"\n",
    "    packs = df[column].str.extract(regex_)\n",
    "    packs['package'] = packs[packs.columns[0:]].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
    "    packs = packs.loc[:, ['package']]\n",
    "    return packs.loc[:, ['package']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16355439",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_package = r'(\\d+x\\d+\\w+)|(\\d+ x \\d+\\w+)|(\\d+\\.+\\d+\\w+)|(\\d+\\.+\\d+ \\w+)|(\\d+ ml)|(\\d+ g)|(\\d+\\w+)|(\\d+ \\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting package\n",
    "df_similars_ext['package'] = package_extract(df_similars_ext, 'product_name', reg_package)\n",
    "df_similars_ext['package_candidate'] = package_extract(df_similars_ext, 'candidate', reg_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb61bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package similarity\n",
    "df_similars_ext['package_ratio'] = df_similars_ext.apply(lambda x: fuzz.token_sort_ratio(x['package'],\\\n",
    "                                                                                x['package_candidate']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afbbc8",
   "metadata": {},
   "source": [
    "### c) Tansforming product names into integers (easier to compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a680728",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_index_dict = dict(zip(df_tf['product_name'], df_tf.index))\n",
    "index_product_dict = dict(zip(df_tf.index, df_tf['product_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['product_name', 'candidate']:\n",
    "    df_similars_ext[col] = df_similars_ext[col].map(product_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similars_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86081e",
   "metadata": {},
   "source": [
    "### d) Package filter + Column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Package Threshold: {threshold_package}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5624502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_similars_ext[df_similars_ext['package_ratio'] > threshold_package].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.loc[:, ['product_name', 'candidate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce2606",
   "metadata": {},
   "source": [
    "### e ) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6282b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group_track_df(groups_df, track_df, product, applicants_list):\n",
    "    if groups_df.shape[0] == 0:\n",
    "        group_id = 0\n",
    "    else:\n",
    "        group_id = groups_df['group_id'].max() + 1\n",
    "    if track_df.shape[0] == 0:\n",
    "        track_id = 0\n",
    "    else:\n",
    "        track_id = track_df['group_id'].max() + 1\n",
    "        \n",
    "    df_temp_group = pd.DataFrame({\n",
    "        'group_id': group_id,\n",
    "        'leader': product,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    df_temp_track = pd.DataFrame({\n",
    "        'group_id': track_id,\n",
    "        'member': applicants_list\n",
    "        })\n",
    "    \n",
    "    return df_temp_group, df_temp_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_concat_groups(groups_df, track_df, index_, applicants_list):\n",
    "    # verify if any of the applicants is already assigned to a group, if not:    \n",
    "    if track_df[track_df['member'].isin(applicants_list)].shape[0] == 0:\n",
    "        # create df for the group\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, applicants_list)\n",
    "        # concat group to the global groups df\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        # concat track group to track global groups df\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    else:\n",
    "        # get the group ids where all of the candidates are assigned\n",
    "        groups_id_list = list(track_df[track_df['member'].isin(applicants_list)]['group_id'].unique())\n",
    "        # locate where the group is\n",
    "        select_df = groups_df[groups_df['group_id'].isin(groups_id_list)]\n",
    "        # list of actual members of the group\n",
    "        already_members = list(pd.unique(select_df[['leader', 'member']].values.ravel('K')))\n",
    "        # union of already members + apliccants list --> idea: get a unique selection of a wider spectrum\n",
    "        concatenated_list = list(set(already_members + applicants_list))\n",
    "        # remove group from global groups and track dataframes\n",
    "        groups_df = groups_df[~groups_df['group_id'].isin(groups_id_list)].copy()\n",
    "        track_df = track_df[~track_df['group_id'].isin(groups_id_list)]\n",
    "        # re-create both: groups & track - global dfs\n",
    "        tmp_group_df, tmp_track_df = create_group_track_df(groups_df, track_df, index_, concatenated_list)\n",
    "        # add the new set to both: groups & track - global dfs\n",
    "        groups_df = pd.concat([groups_df, tmp_group_df], axis=0).reset_index(drop=True)\n",
    "        track_df = pd.concat([track_df, tmp_track_df], axis=0).reset_index(drop=True)\n",
    "    return groups_df, track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_name_replacement(df, dic_):\n",
    "    df['product_name'] = df['product_name'].map(dic_)\n",
    "    df['candidate'] = df['candidate'].map(dic_)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dbda0",
   "metadata": {},
   "source": [
    "### f) Procedure: for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_leaders = df_clean['product_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec27d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_leaders), len(df_similars['match'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23838aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time before\n",
    "t_bef_group = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe definition\n",
    "groups_df = pd.DataFrame(columns=['group_id', 'leader', 'member'])\n",
    "track_df = pd.DataFrame(columns=['group_id', 'member'])\n",
    "\n",
    "for leader in clean_leaders:\n",
    "    select_df = df_clean[df_clean['product_name'] == leader] \n",
    "    applicants_list = list(pd.unique(select_df[['product_name', 'candidate']].values.ravel('K')))\n",
    "    groups_df, track_df = verify_and_concat_groups(groups_df, track_df, leader, applicants_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38279163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time run\n",
    "t_run = time.time()-t_bef_group\n",
    "print(f'Time to run procedure: {round(t_run/60, 3)} minutes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21244b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of groups: {len(groups_df[\"group_id\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing product names\n",
    "groups_df['leader'] = groups_df['leader'].map(index_product_dict)\n",
    "groups_df['member'] = groups_df['member'].map(index_product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830aa246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete run time\n",
    "t_complete = time.time()-t_initial\n",
    "print(f'Time to run it all: {round(t_complete/60, 3)} minutes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352f704",
   "metadata": {},
   "source": [
    "## 6. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b2b8b",
   "metadata": {},
   "source": [
    "### 6.1 Products added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8dda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_products = df_tf['product_name'].unique()\n",
    "len(original_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_products = pd.unique(groups_df[['leader', 'member']].values.ravel('K'))\n",
    "len(added_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_added = []\n",
    "for prod_ in original_products:\n",
    "    if prod_ not in added_products:\n",
    "        not_added.append(prod_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05863699",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of products without group: {len(not_added)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63210cb7",
   "metadata": {},
   "source": [
    "### Who are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2625ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_added[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86aa0f4",
   "metadata": {},
   "source": [
    "### 6.2 Duplicated leaders / members ?? (in 2 or more groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52858cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniques: group_id - leader\n",
    "leaders_df = groups_df[['group_id', 'leader']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated leaders\n",
    "leaders_df[leaders_df['leader'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniques: group_id - member\n",
    "members_df = groups_df[['group_id', 'member']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated members\n",
    "members_df[members_df['member'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fca215",
   "metadata": {},
   "source": [
    "### 6.3 Adding not matched products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de57532",
   "metadata": {},
   "source": [
    "Products not added to the groups dataframe are because previously they demonstrated low similarity on the clusters generated with TF-IDF + Cosine Similarity layer. This why they are added as \"individual groups\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2680f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = groups_df['group_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70089615",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_added_df = pd.DataFrame(data={\n",
    "                    'group_id': range(max_id, max_id + len(not_added)),\n",
    "                    'leader': not_added,\n",
    "                    'member': not_added})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b492523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to groups_df\n",
    "groups_df = pd.concat([groups_df, not_added_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acae51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to track df\n",
    "track_df = pd.concat([track_df, not_added_df.loc[:, ['group_id', 'member']]], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f0ab1f",
   "metadata": {},
   "source": [
    "### 6.4 Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = groups_df.sort_values(by=['leader', 'member']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8864b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.to_csv(f'outputs/groups_{country}_{threshold_products}_{threshold_package}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233d375",
   "metadata": {},
   "source": [
    "### 6.5 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groups_df['leader'].unique()), len(groups_df['member'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df[(groups_df['leader'].str.contains('coca'))|(groups_df['member'].str.contains('coca'))][:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bac24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caea584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5be687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ff121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb4976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b24b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
